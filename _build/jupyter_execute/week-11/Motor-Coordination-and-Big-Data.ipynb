{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a93d8b-f46d-496c-a982-07fffd9c789a",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/neurologic/Neurophysiology-Lab/blob/main/week-11/Motor-Coordination-and-Big-Data.ipynb\" target=\"_blank\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a> Â  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850eb426-07d8-4407-82f1-f163a2c960b6",
   "metadata": {
    "id": "850eb426-07d8-4407-82f1-f163a2c960b6"
   },
   "source": [
    "<a id=\"intro\"></a>\n",
    "# Motor Coordination and Big Data\n",
    "\n",
    "This notebook provides tools for interacting with multi-channel EMG data collected using differential electrodes, Backyard Brains amplifiers, Nidaq acquisition hardware, and Bonsai-rx recording software. \n",
    "\n",
    "Throughout the notebook, you will plot both raw and processed data.\n",
    "- You can interact with the plots by zooming in and panning. <br>\n",
    "- You can save the current plot view at any time by hitting the \"download\" icon - it will save to your Downloads folder. Make sure to re-name the auto-generated file and make notes about what you plotted right away. <br>\n",
    "\n",
    "The plotting tools available in this notebook include:\n",
    "- raw EMG data with each channel plotted separately\n",
    "- emg amplitude envelopes with each channel plotted separately\n",
    "- selected subsets of emg amplitude envelopes overlaid on the same plot\n",
    "- 3D plotting of the first 3 principal components of muscle activity for a specific range of data selected\n",
    "\n",
    "The data processing and analysis tools available in this notebook include:\n",
    "- amplitude envelope smoothing\n",
    "- data range selection within a file\n",
    "- correlation of activity (of the amplitude envelopes) across recording channels\n",
    "- Principle Component Analysis on all recorded channels (channels may be dropped from the analysis in the step when you load the data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zIt8pCksxZic",
   "metadata": {
    "id": "zIt8pCksxZic"
   },
   "source": [
    "<a id=\"toc\"></a>\n",
    "# Table of Contents\n",
    "1. [Introduction](#intro)\n",
    "2. [Setup](#setup)\n",
    "3. [Part I. Raw EMG Signal](#one)\n",
    "4. [Part II. Select Data](#two)\n",
    "5. [Part III. EMG envelope](#three)\n",
    "6. [Part IV. Muscle Coordination](#four)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GsbjCNcAw9VA",
   "metadata": {
    "id": "GsbjCNcAw9VA"
   },
   "source": [
    "# Setup\n",
    "[toc](#toc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "avekklfgakdL",
   "metadata": {
    "cellView": "form",
    "id": "avekklfgakdL",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@markdown Run this code cell to load packages and { display-mode: \"form\" }\n",
    "#@markdown initialize the notebook.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import csv\n",
    "from scipy.signal import hilbert,medfilt,resample\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from datetime import datetime,timezone,timedelta\n",
    "pal = sns.color_palette(n_colors=15)\n",
    "pal = pal.as_hex()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r9t8zvJfY_V2",
   "metadata": {
    "cellView": "form",
    "id": "r9t8zvJfY_V2",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@markdown **TASK:** Run this code cell to mount your Google Drive. { display-mode: \"form\" }\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ovioprV4yvkn",
   "metadata": {
    "cellView": "form",
    "id": "ovioprV4yvkn",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@markdown **TASK:** Run this code cell to load the EMG dataset you will explore and analyze. { display-mode: \"form\" }\n",
    "\n",
    "emg_filepath = \"file path in colab\" #@param\n",
    "\n",
    "sampling_rate = NaN #@param\n",
    "number_channels = NaN #@param\n",
    "drop_channels = [] #@param\n",
    "\n",
    "filepath = Path(emg_filepath)\n",
    "\n",
    "# No need to edit below this line\n",
    "#################################\n",
    "emg = np.fromfile(Path(filepath), dtype = np.float64)\n",
    "emg = emg.reshape(-1,number_channels)\n",
    "dur = np.shape(emg)[0]/sampling_rate\n",
    "print('duration of recording was %0.2f seconds' %dur)\n",
    "newfs = 2500\n",
    "chunksize = int(sampling_rate/newfs)\n",
    "emg = emg[0::chunksize,:]\n",
    "newfs = np.shape(emg)[0]/dur\n",
    "\n",
    "# nerve = y_data[:,nerve_channel] - np.median(y_data[:,nerve_channel],0)\n",
    "time = np.linspace(0,np.shape(emg)[0]/newfs,np.shape(emg)[0])\n",
    "# muscle = y_data[:,muscle_channel]\n",
    "\n",
    "column_names = [str(i) for i in np.arange(0,number_channels)]\n",
    "df_emg = pd.DataFrame(data = emg, columns = column_names)\n",
    "if len(drop_channels)>0:\n",
    "  for chan in drop_channels:\n",
    "    df_emg = df_emg.drop(columns = str(chan))\n",
    "  number_channels = number_channels - len(drop_channels)\n",
    "\n",
    "# Use rectfication and gaussian smoothing on EMG to get mean-centered rate\n",
    "df_rate = pd.DataFrame({})\n",
    "filter_dur = 0.01 #@param\n",
    "filtert = int(filter_dur*sampling_rate)\n",
    "for h in list(df_emg.columns): # rename headers as input channels\n",
    "    y = df_emg[h] - np.mean(df_emg[h])\n",
    "    y = np.abs(y) #takes the absolute value of \n",
    "    y = scipy.ndimage.gaussian_filter(y,filtert)\n",
    "    df_rate[h] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c80eb80-1d17-47bb-81a8-023bf0c2476d",
   "metadata": {
    "id": "0c80eb80-1d17-47bb-81a8-023bf0c2476d"
   },
   "source": [
    "<a id=\"one\"></a>\n",
    "# Part I. Plot the raw EMG signal from each muscle\n",
    "[toc](#toc)\n",
    "\n",
    "The amplitude units of the EMG signal are in Volts, but the amplitude was amplified before being recorded. The amplification factor was approximately 1000, so 1V recorded was really 1mV measured at the electrode. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8290362d-2e74-4fd3-acd3-e4ef54467a38",
   "metadata": {
    "cellView": "form",
    "id": "8290362d-2e74-4fd3-acd3-e4ef54467a38",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@markdown **TASK:** First, specify a time range to plot. { display-mode: \"form\" }\n",
    "#@markdown This is just necessary because these data files are so large.\n",
    "#@markdown If you tried to plot all of the data at once the Google Colab kernel will \"die.\"\n",
    "#@markdown If you need a plot of the whole time range of the recording, let me know \n",
    "#@markdown and I can make one for you using a program local to my computer. \n",
    "#@markdown >Note: You could look at the simulataneously recorded\n",
    "#@markdown video for guidance on time ranges to peak at if needed.\n",
    "#@markdown <br> If you try to plot more than 200 seconds total of data\n",
    "#@markdown (so about 20-30 seconds for 9 channels or 40-60 seconds for 5 channels), \n",
    "#@markdown the plot will \"time out\" and not show up.\n",
    "\n",
    "time_range = [20, 40] #@param\n",
    "\n",
    "#@markdown Then, Run this cell to plot the raw EMG data.\n",
    "#@markdown You can zoom in and scroll around to explore the data. \n",
    "\n",
    "\n",
    "plotmask = ((time>time_range[0]) & (time<time_range[1]))\n",
    "fig = make_subplots(rows=number_channels, cols=1,\n",
    "                    vertical_spacing=0,\n",
    "                    shared_xaxes=True)\n",
    "for i,chan in enumerate(list(df_emg.columns)):\n",
    "  fig.add_trace(go.Scatter(x = time[plotmask], y = df_emg[plotmask][chan].values,\n",
    "                         name=chan),\n",
    "                row=i+1,col=1)\n",
    "fig.update_layout(xaxis_title=\"time(seconds)\", \n",
    "                  yaxis_title='amplitude',width=800, height=1000)\n",
    "# fig.layout.yaxis.showticklabels=False\n",
    "print('Task completed at ' + str(datetime.now(timezone(-timedelta(hours=5)))))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1f1545-2f25-4bfe-be34-1dfb7ca3444e",
   "metadata": {
    "id": "0d1f1545-2f25-4bfe-be34-1dfb7ca3444e"
   },
   "source": [
    "<a id=\"two\"></a>\n",
    "# Part II. Plot the rectified, smoothed \"amplitude envelope\"\n",
    "[toc](#toc)\n",
    "\n",
    "This is a type of *signal processing* that transforms raw EMG activity (a bipolar signal - both positive and negative values) into what we refer to as the *amplitude envelope* of the EMG activity. The \"smoothing\" of the envelope results in a waveform that reflects both the amplitude and the rate of the raw EMG signal (accounts for both spatial and temporal summation). Therefore, absolute voltage information is lost, but you can still compare relative voltage across channels and across recordings that used the same electrode configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04522a80-6411-4c81-b24e-358987ac64dc",
   "metadata": {
    "cellView": "form",
    "id": "04522a80-6411-4c81-b24e-358987ac64dc",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@markdown **TASK:** First, specify a time range to plot. { display-mode: \"form\" }\n",
    "#@markdown This is just necessary because these data files are so large.\n",
    "#@markdown If you tried to plot all of the data at once the Google Colab kernel will \"die.\"\n",
    "#@markdown If you need a plot of the whole time range of the recording, let me know \n",
    "#@markdown and I can make one for you using a program local to my computer. \n",
    "#@markdown >Note: You could look at the simulataneously recorded\n",
    "#@markdown video for guidance on time ranges to peak at if needed.\n",
    "#@markdown <br> If you try to plot more than 200 seconds total of data\n",
    "#@markdown (so about 20-30 seconds for 9 channels or 40-60 seconds for 5 channels), \n",
    "#@markdown the plot will \"time out\" and not show up.\n",
    "\n",
    "time_range = [0, 60] #@param\n",
    "\n",
    "#@markdown Then, Run this cell to plot the envelope of the EMG data.\n",
    "#@markdown You can zoom in and scroll around to explore the data. \n",
    "\n",
    "\n",
    "plotmask = ((time>time_range[0]) & (time<time_range[1]))\n",
    "\n",
    "fig = make_subplots(rows=number_channels, cols=1,\n",
    "                    vertical_spacing=0,\n",
    "                    shared_xaxes=True)\n",
    "for i,chan in enumerate(list(df_rate.columns)):\n",
    "  # if plot_raw:\n",
    "  #   fig.add_trace(go.Scatter(x = time, y = (df_emg[chan].values)/5,\n",
    "  #                        name=chan),\n",
    "  #               row=i+1,col=1)\n",
    "  fig.add_trace(go.Scatter(x = time[plotmask], y = df_rate[plotmask][chan].values,\n",
    "                         name=chan),\n",
    "                row=i+1,col=1)\n",
    "fig.update_layout(xaxis_title=\"time(seconds)\", \n",
    "                  yaxis_title='amplitude',width=800, height=1000)\n",
    "\n",
    "print('Task completed at ' + str(datetime.now(timezone(-timedelta(hours=5)))))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-fNHY6B_23At",
   "metadata": {
    "cellView": "form",
    "id": "-fNHY6B_23At",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@markdown Overlay channels on same axis { display-mode: \"form\" }\n",
    "\n",
    "#@markdown **TASK:** First, specify a time range and set of channels to plot.\n",
    "#@markdown Remember that the first channel is numbered 0.\n",
    "#@markdown >Note: If you plot less channels, you can plot more time.\n",
    "#@markdown If the plot does not show up after the cell finishes, pick less data.\n",
    "\n",
    "time_range = [35, 60] #@param\n",
    "channels_to_plot = [2,4] #@param\n",
    "\n",
    "#@markdown Then, Run this cell to make an overlaid plot \n",
    "#@markdown of the envelope of the EMG data on the selected channels.\n",
    "#@markdown You can zoom in and scroll around to explore the data. \n",
    "\n",
    "plotmask = ((time>time_range[0]) & (time<time_range[1]))\n",
    "\n",
    "fig = go.Figure()\n",
    "for i,chan in enumerate(channels_to_plot):\n",
    "  chan = str(chan)\n",
    "  fig.add_trace(go.Scatter(x = time[plotmask], y = df_rate[plotmask][chan].values,\n",
    "                         name=chan,opacity=1))\n",
    "fig.update_layout(xaxis_title=\"time(seconds)\", \n",
    "                  yaxis_title='amplitude',width=800, height=500)\n",
    "\n",
    "print('Task completed at ' + str(datetime.now(timezone(-timedelta(hours=5)))))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jE6GzivbzjVP",
   "metadata": {
    "id": "jE6GzivbzjVP"
   },
   "source": [
    "<a id=\"three\"></a>\n",
    "# Part III. Analyze a selection of the data. \n",
    "[toc](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb7f4d2-384b-4161-8c57-9d37750c91bc",
   "metadata": {
    "cellView": "form",
    "id": "ccb7f4d2-384b-4161-8c57-9d37750c91bc",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@markdown Pick a time window to analyze that has the section  { display-mode: \"form\" }\n",
    "#@markdown of movement you want to analyze \n",
    "#@markdown and enter it in the code cell below.\n",
    "#@markdown > Note: get the time by hovering over the data plot. \n",
    "#@markdown - **start** = the start time of the section you want to analyze (seconds).\n",
    "#@markdown - **stop** = the stop time of the section you want to analyze (seconds).\n",
    "\n",
    "start =  36.5#@param {type:\"number\"}\n",
    "stop = 50 #@param {type:\"number\"}\n",
    "\n",
    "#@markdown <b>Task:</b> After you have specified the start and stop times,\n",
    "#@markdown run this cell to execute the variable assignment.\n",
    "# df_vid_selection = df_vid[((df_vid['time']>(start)) & (df_vid['time']<(stop)))] # select start:stop section\n",
    "# df_emg_select = df_emg[((time>start) & (time<stop))]\n",
    "df_rate_select = df_rate[((time>start) & (time<stop))]\n",
    "time_select = time[((time>start) & (time<stop))]\n",
    "\n",
    "print('all set - analysis domain defined')\n",
    "print('Task completed at ' + str(datetime.now(timezone(-timedelta(hours=5)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f7e282-b954-42bd-8ea2-b5edb134ec99",
   "metadata": {
    "id": "84f7e282-b954-42bd-8ea2-b5edb134ec99"
   },
   "source": [
    "<a id=\"four\"></a>\n",
    "# Part IV. Muscle coordination\n",
    "[toc](#toc)\n",
    "\n",
    "Think about how you would qualitatively describe the relationship between the two muscle signals that you plotted. The correlation metric is often helpful to quantify the relationship between signals. Essentially, correlation is the measure of how two or more variables are related to one another. https://en.wikipedia.org/wiki/Correlation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387e96e-32ec-461c-a242-f7070d9356aa",
   "metadata": {
    "cellView": "form",
    "id": "0387e96e-32ec-461c-a242-f7070d9356aa",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@markdown <b>Task:</b> Run this cell to calculate the { display-mode: \"form\" }\n",
    "#@markdown mathematical correlation values between the two signals.\n",
    "#@markdown The results will be shown in table and matrix format.\n",
    "\n",
    "# No need to edit this code cell\n",
    "################################\n",
    "print('correlation matrix:')\n",
    "p_corr = df_rate_select.corr()\n",
    "display(p_corr)\n",
    "hfig, ax = plt.subplots(1)\n",
    "sns.heatmap(p_corr, annot=True);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cKZJFHfn9QH-",
   "metadata": {
    "id": "cKZJFHfn9QH-"
   },
   "source": [
    "<a id=\"five\"></a>\n",
    "# Part V. Dimensionality Reduction\n",
    "[toc](#toc)\n",
    "\n",
    "Use principal component analysis to observe the activity of all muscles simultaneously in the context of the dominant signals from the population activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ITn8e7zJ2Egx",
   "metadata": {
    "cellView": "form",
    "id": "ITn8e7zJ2Egx",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@markdown <b>Task:</b> Run this cell to do a Principal Component Analysis { display-mode: \"form\" }\n",
    "#@markdown (PCA) on the selected data.\n",
    "#@markdown You will get a plot of the explained variance for each PC.\n",
    "\n",
    "df = df_rate_select\n",
    "df =(df - df.mean()) / df.std()\n",
    "n_components=df.shape[1] # if try to take more components than have channels, use amount of channels\n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(df)\n",
    "df_pca = pd.DataFrame(pca.transform(df), columns=['PC%i' % i for i in range(n_components)], index=df.index)\n",
    "print('Your data has now been transformed into ' + str(n_components) + ' principle components.')\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df_pca.columns, y=pca.explained_variance_ratio_, \n",
    "                                 mode='markers',marker_size=15,line_color='black'))\n",
    "fig.update_layout(xaxis_title=\"Principal Components\", \n",
    "                  yaxis_title='Explained Variance', width=400, height=350)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Yt8diIxB2uQ6",
   "metadata": {
    "cellView": "form",
    "id": "Yt8diIxB2uQ6",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@markdown <b>Task:</b> Run this cell to plot the data in the space defined by { display-mode: \"form\" }\n",
    "#@markdown the first three principle components of the selected data.\n",
    "#@markdown The start and stop locations of the trajectory are marked by green and purple dots (respectively).\n",
    "#@markdown > Note: The plot sometimes starts zoomed far in. \n",
    "#@markdown Hit the \"home\" button and/or zoom out. You can then \n",
    "#@markdown zoom back in as needed.\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter3d(x=df_pca['PC0'], y=df_pca['PC1'], z=df_pca['PC2'],\n",
    "                                   mode='markers',name='trajectory',marker_size=1,line_color='black'))\n",
    "fig.add_trace(go.Scatter3d(x=[df_pca['PC0'].values[0]], y=[df_pca['PC1'].values[0]], z=[df_pca['PC2'].values[0]],\n",
    "                                   mode='markers',name='start',marker_size=10,line_color='green'))\n",
    "fig.add_trace(go.Scatter3d(x=[df_pca['PC0'].values[-1]], y=[df_pca['PC1'].values[-1]], z=[df_pca['PC2'].values[-1]],\n",
    "                                   mode='markers',name='stop',marker_size=10,line_color='purple'))\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "        xaxis = dict(title = 'PC0'),\n",
    "        yaxis = dict(title = 'PC1'),\n",
    "        zaxis = dict(title = 'PC2')),\n",
    "    width=600, height = 600)\n",
    "    \n",
    "   \n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NotebookColab_EMG_NiDAQ_MultiChannel_Video_Audio.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
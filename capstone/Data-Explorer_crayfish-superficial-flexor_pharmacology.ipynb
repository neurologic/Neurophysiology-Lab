{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32647951-7dcf-4553-b42a-5d8508d95cf9",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/neurologic/Neurophysiology-Lab/blob/main/capstone/Data-Explorer_crayfish-superficial-flexor_pharmacology.ipynb\" target=\"_blank\" rel=\"noopener noreferrer\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a> Â  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40761f4a-e1a9-4b67-9730-5d554d380e91",
   "metadata": {},
   "source": [
    "# Duncan - Data Explorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b445ff-7cf7-442e-bb25-83afe6d5a3fb",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# Superficial Flexor: Postsynaptic Activity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a849ba-985d-401c-a345-78f3dea2fe86",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "# Setup\n",
    "\n",
    "\n",
    "Import and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563bc67c-8936-49fa-ac9c-5e51f3f6fc89",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title {display-mode: \"form\" }\n",
    "\n",
    "#@markdown Run this code cell to import packages and define functions \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import ndimage\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import hilbert,medfilt,resample, find_peaks, unit_impulse\n",
    "import seaborn as sns\n",
    "from datetime import datetime,timezone,timedelta\n",
    "pal = sns.color_palette(n_colors=15)\n",
    "pal = pal.as_hex()\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib.ticker import (AutoMinorLocator, MultipleLocator)\n",
    "from ipywidgets import widgets, interact, interactive, interactive_output\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")\n",
    "\n",
    "print('Task completed at ' + str(datetime.now(timezone(-timedelta(hours=5)))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec2161-a892-4f83-904d-c69de977cff1",
   "metadata": {},
   "source": [
    "Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e89f46-51f1-485c-a8d2-f36703e2da44",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title {display-mode: \"form\" }\n",
    "\n",
    "#@markdown Run this cell to mount your Google Drive.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print('Task completed at ' + str(datetime.now(timezone(-timedelta(hours=5)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0520411-162e-4891-ac66-fb797be49a1f",
   "metadata": {},
   "source": [
    "## Import data \n",
    "\n",
    "Import data digitized with *Nidaq USB6211* and recorded using *Bonsai-rx* as a *.bin* file\n",
    "\n",
    "If you would like sample this Data Explorer, but do not have data, you can download the following examples (two channels digitized at 40000). Channel 0 is the signal measured from N3 and Channel 1 is the signal measured from the Superficial Flexor muscle. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb9bad0-84d7-49f1-8a61-5e61bdea8231",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title {display-mode: \"form\" }\n",
    "\n",
    "#@markdown Specify the file path \n",
    "#@markdown to your recorded data on Drive (find the filepath in the colab file manager:\n",
    "\n",
    "filepath = \"full filepath goes here\"  #@param \n",
    "# filepath = '/Users/kperks/Downloads/Duncan_final/Capstone_McKee0.bin' \n",
    "\n",
    "#@markdown Specify the sampling rate and number of channels recorded.\n",
    "\n",
    "sampling_rate = None #@param\n",
    "number_channels = None #@param\n",
    "\n",
    "\n",
    "# downsample = False #@param\n",
    "# newfs = 10000 #@param\n",
    "\n",
    "#@markdown After you have filled out all form fields, \n",
    "#@markdown run this code cell to load the data. \n",
    "\n",
    "filepath = Path(filepath)\n",
    "\n",
    "# No need to edit below this line\n",
    "#################################\n",
    "data = np.fromfile(Path(filepath), dtype = np.float64)\n",
    "data = data.reshape(-1,number_channels)\n",
    "data_dur = np.shape(data)[0]/sampling_rate\n",
    "print('duration of recording was %0.2f seconds' %data_dur)\n",
    "\n",
    "fs = sampling_rate\n",
    "# if downsample:\n",
    "   ## newfs = 10000 #downsample emg data\n",
    "    # chunksize = int(sampling_rate/newfs)\n",
    "    # data = data[0::chunksize,:]\n",
    "    # fs = int(np.shape(data)[0]/data_dur)\n",
    "\n",
    "time = np.linspace(0,data_dur,np.shape(data)[0])\n",
    "\n",
    "print('Data upload completed at ' + str(datetime.now(timezone(-timedelta(hours=5)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d4210-b618-45f2-af8f-828c34d78329",
   "metadata": {},
   "source": [
    "## Detect PSP peaks\n",
    "\n",
    "\n",
    "For a more extensive ***RAW*** Data Explorer than the one provided in the above figure, use the [DataExplorer.py](https://raw.githubusercontent.com/neurologic/Neurophysiology-Lab/main/howto/Data-Explorer.py) application found in the [howto section](https://neurologic.github.io/Neurophysiology-Lab/howto/Dash-Data-Explorer.html) of the course website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd520a54-7a81-4c6c-a85c-f9ccb23a9b56",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@markdown Run this cell to create an interactive plot with a slider to scroll \n",
    "#@markdown through the signal\n",
    "#@markdown and set an appropriate event detection threshold and noise threshold. \n",
    "\n",
    "slider_xrange = widgets.FloatRangeSlider(\n",
    "    min=0,\n",
    "    max=data_dur,\n",
    "    value=(0,data_dur),\n",
    "    step= 0.1,\n",
    "    readout=True,\n",
    "    continuous_update=False,\n",
    "    description='Time Range (s)',\n",
    "    style = {'description_width': '200px'})\n",
    "slider_xrange.layout.width = '600px'\n",
    "\n",
    "slider_yrange = widgets.FloatRangeSlider(\n",
    "    min=-2,\n",
    "    max=2,\n",
    "    value=[-0.9,0.1],\n",
    "    step=0.01,\n",
    "    continuous_update=False,\n",
    "    readout=True,\n",
    "    description='yrange',\n",
    "    style = {'description_width': '200px'})\n",
    "slider_yrange.layout.width = '600px'\n",
    "\n",
    "slider_text = widgets.Text(\n",
    "    value='0.04',\n",
    "    placeholder='0.04',\n",
    "    description='time to peak (s)',\n",
    "    style = {'description_width': '200px'},\n",
    "    disabled=False\n",
    ")\n",
    "select_channel = widgets.Select(\n",
    "    options=np.arange(np.shape(data)[1]), # start with a single trial on a single bout... it will update when runs ; old: np.arange(len(trial_times)),\n",
    "    value=0,\n",
    "    #rows=10,\n",
    "    description='Channel',\n",
    "    style = {'description_width': '50px'},\n",
    "    disabled=False\n",
    ")\n",
    "select_channel.layout.width = '100px'\n",
    "select_channel.layout.height = '50px'\n",
    "\n",
    "# slider_threshold = widgets.FloatSlider(\n",
    "#     min=0,\n",
    "#     max=5,\n",
    "#     value=0.2,\n",
    "#     step=0.005,\n",
    "#     readout_format='.3f',\n",
    "#     continuous_update=False,\n",
    "#     readout=True,\n",
    "#     description='event detection threshold',\n",
    "#     style = {'description_width': '200px'})\n",
    "# slider_threshold.layout.width = '600px'\n",
    "\n",
    "radio_polarity = widgets.RadioButtons(\n",
    "    options=[1, -1],\n",
    "    value=1,\n",
    "    description='peaks polarity',\n",
    "    layout={'width': 'max-content'},\n",
    "    style = {'description_width': '100px'},\n",
    "    disabled=False\n",
    ")\n",
    "radio_polarity.layout.width = '300px'\n",
    "\n",
    "# ui_peaks = widgets.HBox([select_channel, radio_polarity, slider_threshold])\n",
    "\n",
    "# detect_type_radio = widgets.RadioButtons(\n",
    "#     options=['peak', 'level crossing positive', 'level crossing negative'],\n",
    "#     value='level crossing positive', # Defaults to 'level crossing'\n",
    "#     layout={'width': 'max-content'}, # If the items' names are long\n",
    "#     description='Type of event detection',\n",
    "#     style = {'description_width': '200px'},\n",
    "#     disabled=False\n",
    "# )\n",
    "\n",
    "iei_text = widgets.Text(\n",
    "    value='0.01',\n",
    "    placeholder='0.01',\n",
    "    description='minimum interval (s)',\n",
    "    style = {'description_width': '200px'},\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "noise_amp_text = widgets.Text(\n",
    "    value='0.06',\n",
    "    placeholder='0.06',\n",
    "    description='threshold amplitude (V)',\n",
    "    style = {'description_width': '200px'},\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def update_plot(chan_,xrange,yrange,polarity,iei,noise_amp,onset):\n",
    "    fig, ax = plt.subplots(figsize=(10,5),num=1); #specify figure number so that it does not keep creating new ones\n",
    "    \n",
    "    signal = data[:,chan_].reshape(-1)\n",
    "    # signal = signal-np.median(signal)\n",
    "\n",
    "    \n",
    "    iei = float(iei)\n",
    "    noise_amp = float(noise_amp)\n",
    "    onset = float(onset)\n",
    "    prepeak_base = int(onset*fs)\n",
    "    \n",
    "    if iei>1/fs:\n",
    "        d = iei*fs #minimum time allowed between distinct events\n",
    "\n",
    "        # if thresh_ >=0:\n",
    "        #     r = find_peaks(signal,height=thresh_,distance=d)\n",
    "        # if thresh_ <0:\n",
    "        #     r = find_peaks(-1*signal,height=-1*thresh_,distance=d)\n",
    "        # trial_times = r[0]/fs\n",
    "\n",
    "        if polarity == 1:\n",
    "            # r_thresh = find_peaks(signal,height=thresh_,distance=d)\n",
    "            r_prom = find_peaks(signal,distance=d,prominence=noise_amp)\n",
    "            r_ind = r_prom[0] #np.intersect1d(r_thresh[0],r_prom[0])\n",
    "            # lagging_peak_amp = r[1]['peak_heights']\n",
    "            peak_amp = signal[r_ind]\n",
    "            base_amp = signal[r_ind-prepeak_base]\n",
    "            # ax.hlines(thresh_, xrange[0],xrange[1],linestyle='--',color='green')\n",
    "        if polarity == -1:\n",
    "            # r = find_peaks(-1*lagging_signal,height=-1*thresh_,distance=d,prominence=float(noise_amp))\n",
    "            # r_thresh = find_peaks(-1*signal,height=thresh_,distance=d)\n",
    "            r_prom = find_peaks(-1*signal,distance=d,prominence=noise_amp)\n",
    "            r_ind = r_prom[0] #np.intersect1d(r_thresh[0],r_prom[0])\n",
    "            # lagging_peak_amp = -1*r[1]['peak_heights']\n",
    "            peak_amp = signal[r_ind]\n",
    "            base_amp = signal[r_ind-prepeak_base]\n",
    "            # ax.hlines(-thresh_, xrange[0],xrange[1],linestyle='--',color='green')\n",
    "\n",
    "        # peak_times = np.asarray([np.round(s/fs,2) for s in r_ind])\n",
    "        peak_times = np.asarray([s/fs for s in r_ind])\n",
    "\n",
    "        starti = int(xrange[0]*fs)+1\n",
    "        stopi = int(xrange[1]*fs)-1\n",
    "        ax.plot(time[starti:stopi], signal[starti:stopi], color='black')\n",
    "\n",
    "\n",
    "        inwin_inds = (peak_times>(xrange[0])) & (peak_times<(xrange[1]))\n",
    "        ax.scatter(peak_times[inwin_inds],peak_amp[inwin_inds], zorder=3,color='red',s=20)\n",
    "        ax.scatter(peak_times[inwin_inds]-onset,base_amp[inwin_inds], zorder=3,color='green',s=20)\n",
    "\n",
    "        ax.set_ylim(yrange[0],yrange[1])\n",
    "        ax.set_xlim(xrange[0],xrange[1])\n",
    "\n",
    "        ax.xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "\n",
    "        return peak_times, peak_amp-base_amp\n",
    "\n",
    "# w_trials_ = interactive(update_plot, chan_=select_channel, \n",
    "#                         xrange=slider_xrange, \n",
    "#                         thresh_=slider_threshold, iei = iei_text, noise_amp = noise_amp_text);\n",
    "# display(w_trials_)\n",
    "w_peak_detect_all = interactive(update_plot, chan_=select_channel, \n",
    "                        yrange=slider_yrange,xrange=slider_xrange,\n",
    "                                polarity = radio_polarity, iei = iei_text,noise_amp=noise_amp_text,\n",
    "                               onset=slider_text);\n",
    "display(w_peak_detect_all)\n",
    "\n",
    "# w_peak_detect_all = interactive(update_plot, {'chan_':select_channel,\n",
    "#                                      'yrange':slider_yrange, \n",
    "#                                      'xrange':slider_xrange,\n",
    "#                                      'thresh_':slider_threshold,\n",
    "#                                      'polarity':radio_polarity,\n",
    "#                                      'iei':iei_text,\n",
    "#                                      'noise_amp':noise_amp_text});\n",
    "# display(ui_peaks,widgets.HBox([iei_text,noise_amp_text]),w_peak_detect_all,ui_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79dbf5-af08-401a-a78e-fd519d26e921",
   "metadata": {},
   "source": [
    "## Define Bouts\n",
    "\n",
    "To efficiently assess your data with this analysis, make sure to exclude any raw data that does not have a clean (low-noise) signal. For the simultaneously recorded pre- and post-synaptic signals, make sure to exclude raw data in which the post-synaptic electrode was not stably in the cell. The more data you are able to include, the better your spike sorting results will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8648f94-5d73-48ab-ae81-18882f8c31e4",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title {display-mode: \"form\"}\n",
    "\n",
    "#@markdown For this experiment, the entire file should be one long bout, \n",
    "#@markdown but if there were regions that something got messed up or that you want to exclude, you can specify bouts with good data.\n",
    "#@markdown Specify the list of bout ranges as follows: [[start of bout 0, end of bout 0],[start 1, end 1],...]] <br>\n",
    "\n",
    "\n",
    "bouts_list = [[0,10]] #@param\n",
    "\n",
    "#@markdown Then run this code cell to programatically define the list of bouts as 'bouts_list'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8063b5e6-8d85-44e9-b86c-cb2a9207113b",
   "metadata": {},
   "source": [
    "## Save processed data as .csv\n",
    "\n",
    "Specify the \"condition\" for the data you just processed. The condition should be a string (ie. surrounded by quotes).\n",
    "> It will take a minute or so to process and actually save, but the .csv file will be saved to the local \"content\" folder of Google Collaboratory. You can download them individually to your own computer (or move them to your Google Drive) to use again later without re-processing the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d83665d-b435-4e02-9091-4d097b746f5f",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title {display-mode: \"form\"}\n",
    "\n",
    "condition = 'baseline' #@param\n",
    "\n",
    "peak_times,peak_amp = w_peak_detect_all.result\n",
    "\n",
    "mask = []\n",
    "for b_ in bouts_list:\n",
    "    mask.append((peak_times>b_[0]) & (peak_times<b_[1]))\n",
    "mask = sum(mask).astype(bool)\n",
    "\n",
    "df = pd.DataFrame({'time':peak_times[mask],'amp':peak_amp[mask],'number':np.arange(0,sum(mask),1),'condition':condition})\n",
    "\n",
    "df.to_csv('PSP_' + condition + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000e64f-0309-4345-80f5-463340c9bf2e",
   "metadata": {},
   "source": [
    "## Visualize the average raw signal time-locked to PSP peaks.\n",
    "\n",
    "Average across unitary PSPs that are temporally isolated from each other (not temporally summated with another). Average is centered at the PSP peak. Only PSPs within the previously specified bouts are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb9c5b-5f47-4bfc-b088-7d1af2eddb22",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title {display-mode:\"form\"}\n",
    "\n",
    "#@markdown Specify which channel has the intracellular signal. \n",
    "#@markdown Then run this cell to plot the average spike-triggered \n",
    "#@markdown post-synaptic potential for each spike cluster you defined in Part I\n",
    "\n",
    "intracellular_channel = 1 #@param\n",
    "psp_duration = 0.04 #@param\n",
    "\n",
    "slider_xrange = widgets.FloatRangeSlider(\n",
    "    min=-0.05,\n",
    "    max=0.10,\n",
    "    value=(-0.02,0.1),\n",
    "    step=0.005,\n",
    "    readout_format='.3f',\n",
    "    continuous_update=False,\n",
    "    readout=True,\n",
    "    description='xrange (s)'\n",
    ")\n",
    "slider_xrange.layout.width = '600px'\n",
    "\n",
    "def update_plot(xrange):\n",
    "    # No need to edit below this line\n",
    "    #################################\n",
    "    windur = xrange[1]-xrange[0]\n",
    "    winsamps = int(windur * fs)\n",
    "\n",
    "    onset = int(xrange[0]*fs)\n",
    "    offset = int(xrange[1]*fs)\n",
    "\n",
    "    x = np.linspace(xrange[0],xrange[1],offset-onset)\n",
    "    \n",
    "    hfig,ax = plt.subplots(figsize=(8,4))\n",
    "    ax.set_ylabel('volts recorded',fontsize=14)\n",
    "    ax.set_xlabel('seconds',fontsize=14)\n",
    "    # plt.xticks(fontsize=14)\n",
    "    # plt.yticks(fontsize=14)\n",
    "    \n",
    "    trial_t = peak_times[mask]\n",
    "    trial_t_sorted = trial_t[((np.diff(trial_t,prepend=np.NaN)>psp_duration)&(np.diff(trial_t,append=np.NaN)>psp_duration))]\n",
    "    \n",
    "\n",
    "    synwav = np.asarray([data[int(t*fs)+onset:int(t*fs)+offset,intracellular_channel] for t in trial_t_sorted \n",
    "                         if (((int(t*fs)+onset)>0) & (int(t*fs)+offset<np.shape(data)[0]))])\n",
    "    wav_u = np.mean(synwav,0)\n",
    "    wav_std = np.std(synwav,0)\n",
    "    ax.plot(x,wav_u,linewidth = 3,color = 'black');\n",
    "    ax.fill_between(x, wav_u-wav_std, wav_u+wav_std, alpha = 0.25, color = 'purple')\n",
    "    # plt.legend(bbox_to_anchor=[1.5,1], fontsize=14);\n",
    "    ax.set_xlim(xrange[0],xrange[1])\n",
    "    \n",
    "w_psps_sorted_ = interactive(update_plot, xrange=slider_xrange);\n",
    "\n",
    "display(w_psps_sorted_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2593252-178d-4126-affe-27707d9fd49a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compare across conditions \n",
    "\n",
    "Provide a list of the csv files generated in the \"Save processed data as .csv\" step. The code will iterate through each data file and plot the results. You will also see the result of a mono-exponential fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5777bffc-8eae-4288-9880-be9f852f5d3f",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title {display-mode: \"form\"}\n",
    "\n",
    "#@markdown List the full path to each csv file created using the \"adaptation analysis tool.\"\n",
    "file_list = ['PSP_baseline.csv', 'PSP_dopamine.csv'] #@param\n",
    "# file_list = ['adaptation_2_b_.csv','adaptation_5_b_.csv','adaptation_10_b_.csv']\n",
    "\n",
    "#@markdown Then run this code cell to create a dataframe combining the data from all listed files.\n",
    "\n",
    "\n",
    "df = pd.DataFrame({})\n",
    "for f in file_list:\n",
    "    df_ = pd.read_csv(f)\n",
    "    df = pd.concat([df,df_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853eaf85-6a01-4386-ab37-ecf057af1dc1",
   "metadata": {},
   "source": [
    "A **box plot** (or box-and-whisker plot) shows the distribution of quantitative data in a way that facilitates comparisons between variables or across levels of a categorical variable. The box shows the quartiles of the dataset while the whiskers extend to show the rest of the distribution, except for points that are determined to be âoutliersâ using a method that is a function of the inter-quartile range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c139b5d-59b3-4c58-b1fd-4fa6b6989001",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@markdown Run this code cell to create a bo xplot of condition by amplitude\n",
    "\n",
    "x_param = 'condition' #@param\n",
    "y_param = 'amp' #@param\n",
    "\n",
    "hfig,ax = plt.subplots(figsize=(5,4))\n",
    "sns.boxplot(data=df, x=x_param, y=y_param);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd6014-58f3-4745-a838-234d77cc1aeb",
   "metadata": {},
   "source": [
    "A **violin plot** plays a similar role as a box and whisker plot. It shows the distribution of quantitative data across several levels of one (or more) categorical variables such that those distributions can be compared. Unlike a box plot, in which all of the plot components correspond to actual datapoints, the violin plot features a kernel density estimation of the underlying distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a3a362-e265-4f17-9fc2-df791977a86e",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@markdown Run this code cell to create a violin plot of condition by amplitude\n",
    "\n",
    "x_param = 'condition' #@param\n",
    "y_param = 'amp' #@param\n",
    "\n",
    "hfig,ax = plt.subplots(figsize=(5,4))\n",
    "sns.violinplot(data=df, x=x_param, y=y_param, bw=.15, scale=\"count\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d451b557-6777-4492-955e-a41130ad39b9",
   "metadata": {},
   "source": [
    "<hr> \n",
    "Written by Dr. Krista Perks for courses taught at Wesleyan University."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c707588-d5f6-4142-8289-da7ba6a97dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57a8a68c-055e-4af0-ba4d-67d0d67148f1",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a350712e-e145-4475-9588-e3f19469b5ce",
   "metadata": {},
   "source": [
    "<a id=\"one\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fd2b4a-b890-465f-bf33-c2057738789e",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05de192-2baf-4d46-8848-6db1e3b50bff",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6519277-fc86-44fd-a75b-f74cad0efcf1",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
